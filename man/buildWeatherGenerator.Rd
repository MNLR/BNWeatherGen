% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/buildWeatherGenerator.R
\name{buildWeatherGenerator}
\alias{buildWeatherGenerator}
\title{Build a Discrete Bayesian Network Weather Generator.}
\usage{
buildWeatherGenerator(
  y,
  x = NULL,
  structure.learning.algorithm = "tabu",
  structure.learning.args.list = list(),
  param.learning.method = "bayes",
  epochs = 2,
  force.DD = NULL,
  forbid.GG = FALSE,
  forbid.DD = FALSE,
  forbid.DtoG = FALSE,
  force.closest.GD = NULL,
  closest.GD.direction = NULL,
  forbid.GD = FALSE,
  structure.learning.steps = 1,
  fix.intermediate = TRUE,
  structure.learning.algorithm2 = NULL,
  structure.learning.args.list2 = list(),
  structure.learning.algorithm3 = NULL,
  structure.learning.args.list3 = list(),
  keep.dynamic.distance = TRUE,
  remove.past.G = TRUE,
  forbid.backwards = FALSE,
  forbid.past.dynamic.GD = TRUE,
  forbid.dynamic.GG = FALSE,
  forbid.past.DD = FALSE,
  return.intermediate = FALSE,
  compile.junction = FALSE,
  parallelize = FALSE,
  n.cores = NULL,
  cluster.type = "FORK"
)
}
\arguments{
\item{y}{Stations dataset, as output by \code{loadeR::loadStationData()} (see Details)}

\item{x}{By default \code{NULL}, can be used to provide a predictor dataset, as output by
\code{loadeR::loadGridData()}.}

\item{structure.learning.algorithm}{Algorithm used to perform structure learning, with name
as text. Supports all the score-based, constraint-based and hybrid bayesian network structure
learning algorithms from \code{\link[bnlearn]{bnlearn}}.
Refer to \code{Details} for a list of supported algorithms.}

\item{structure.learning.args.list}{List of arguments passed to structure.learning.algorithm,
in particular distance argument if local learning is used. Note that other arguments, e.g.
\code{whitelist}, are an option (check the naming convention, see \code{Details}).
Refer to \code{\link[bnlearn]{bnlearn}} for the specific options.}

\item{param.learning.method}{Either "bayes", for bayesian estimation; or "mle", for 
Maximum Likelihood Estimation.}

\item{epochs}{Number of epochs to consider for Dynamic Bayesian Networks.}

\item{force.DD}{If set to "-", the final DAG will be force to have a link between each station and 
its past. If set to "->" the arc will be forced from past to present, and from present to past if 
set to "<-".}

\item{forbid.GG}{If set to TRUE, arcs between grid or G nodes will be forbidden.}

\item{forbid.DD}{If set to TRUE, arcs between local, i.e. station or D nodes, will be forbidden.}

\item{forbid.DtoG}{If set to TRUE, arcs from D nodes to G nodes will be forbidden.}

\item{force.closest.GD}{Expects a positive integer or \code{NULL}. If not \code{NULL}, each D node will
be linked, see \code{closest.GD.direction}, with the n closest G node(s), where n is
\code{force.closest.GD}.}

\item{closest.GD.direction}{Either \code{NULL}, which lets the structure learning algorithm
decide the direction, "up", which will place the arc(s) in the form \code{D -> G}, or "down",
which will place the arc(s) in the form \code{G -> D}.}

\item{forbid.GD}{If set to TRUE, arcs between G and D nodes will be forbidden. See
\code{Details}.}

\item{structure.learning.steps}{It is used to perform structure learning in up to three steps.
 Note that \code{past} refers to the past epochs when \code{dynamic = TRUE}.
 Refer to \code{Details}.
\itemize{
 \item \code{1} or \code{NULL} (Default) 1 step
 \item \code{2} or \code{c("local", "global")} If \code{dynamic = FALSE} learn first a DAG
 for D nodes, then inject G nodes. If \code{dynamic = TRUE} it equals
 c("local-global", "past")
 \item \code{3} Equals c("local", "global", "past")
 \item \code{c("local-global", "past")} or \code{c("global-local", "past")}.
  Learn first DAG for D and G nodes, then inject past nodes.
 \item \code{c("local", "global-past")} or \code{c("local", "past-global")}.
 Learn first DAG for D nodes, then inject past and G nodes.
 \item \code{c("local-past", "global")} or \code{c("past-local", "global")}.
 Learn first DAG for D and past nodes, then inject G nodes.
 \item \code{c("local", "global", "past")} Learn first DAG for D nodes, then inject G nodes,
 then inject past nodes.
 \item \code{c("local", "past", "global")} Learn first DAG for D nodes, then inject
 past nodes, then inject G nodes.
}
Note that only first two options are valid when \code{dynamic = FALSE}}

\item{fix.intermediate}{Set to TRUE to forbid the creation of new arcs in the next steps
for already built DAGs. See \code{Details}.
\code{structure.learning.algorithm2} and \code{structure.learning.args.list2}. See
 \code{Details}.}

\item{structure.learning.algorithm2}{Same as structure.learning.algorithm for the second
step if \code{structure.learning.steps} is employed. Ignored otherwise.}

\item{structure.learning.args.list2}{Same as structure.learning.args.list for the second
step if \code{structure.learning.steps} is employed. Ignored otherwise.}

\item{structure.learning.algorithm3}{Same as structure.learning.algorithm for the third
step if \code{structure.learning.steps} with 3 steps is employed. Ignored otherwise.}

\item{structure.learning.args.list3}{Same as structure.learning.args.list for the third step
if \code{structure.learning.steps} with 3 steps is employed. Ignored otherwise.
See \code{Details}.}

\item{keep.dynamic.distance}{When \code{dynamic = TRUE} and local learning is employed,
if set to TRUE it will use its corresponding distance (See \code{Details}) between nodes
from diferent epochs.}

\item{remove.past.G}{When \code{dynamic = TRUE} Set to TRUE to remove the past G nodes.}

\item{forbid.backwards}{When \code{dynamic = TRUE}, set to TRUE to forbid arcs going
back in time.}

\item{forbid.past.dynamic.GD}{When \code{dynamic = TRUE}, set to TRUE to forbid arcs in the
form G->D or D->G between different epochs.}

\item{forbid.dynamic.GG}{When \code{dynamic = TRUE} and \code{remove.past.G = FALSE}, set to
TRUE to forbid arcs in the form G-G in the past epochs.}

\item{forbid.past.DD}{When \code{dynamic = TRUE}, set to TRUE to forbid arcs in the form D-D
in the past epochs.}

\item{return.intermediate}{Add the intermediate DAGs to the output, as $intermediateDBN1 and
$intermediateDBN2 (if any) if \code{structure.learning.steps} is employed.}

\item{compile.junction}{Compile the junction tree from BN.fit to compute probabilities. Can be
set to FALSE. Compiling the junction tree is necessary for using exact inference at the
simulating stage.}

\item{parallelize}{Set to \code{TRUE} for parallelization. Refer to the
\code{\link[parallel]{parallel}} and see \code{Details}.}

\item{n.cores}{When \code{parallelize = TRUE}, number of threads to be used, will use
detectCores()-1 if not set.}

\item{cluster.type}{Either "PSOCK" or "FORK". Use the former under Windows systems,
refer to \code{\link[parallel]{parallel}} package.}
}
\value{
An object of type CBN which contains the learnt Bayesian Network.
}
\description{
Builds a discrete weather generator Bayesian network model, using
\href{https://www.bnlearn.com}{bnlearn}. Data should be discretized prior to calling 
the function by the user. The Bayesian network will approximate the Joint Probability 
Distribution of the dataset \code{y} considering the temporal order specified in \code{epochs}.
}
\details{
buildWeatherGenerator() can be used with just a stations dataset. A Grid dataset may be specified
by either using parameter \code{x} or using a "pp.forBN" class object (as output from
\code{preparePredictorsBN()}) for parameter \code{y}. If none is specified the Bayesian
Network may be used as a naive weather generator.

\strong{Structure Learning Algorithms}
Use \code{structure.learning.algorithm} to specify the algorithm for the structure (DAG) learning
process.
Currently it DOES NOT support local discovery algorithms, expect malfuncion if used.
List of supported algorithms:
\code{"hc"}, \code{"tabu"} (score-based), \code{"gs"}, \code{"iamb"}, \code{"fast.iamb"},
\code{"inter.iamb"} (constraint-based),
\code{"mmhc"}, \code{"rsmax2"} (hybrid).
Check their corresponding parameters in \code{\link[bnlearn]{bnlearn}}, arguments may be
passed to the algorithm through
the parameter structure.learning.args.list. Do not forget to set the distance argument
in \code{structure.learning.args.list} for
local learning.

\strong{Two or Three Step Learning}
\itemize{
\item \code{structure.learning.steps} allows to build separate DAGs for each set of nodes.
 Note that by employing the three \code{structure.learning.algorithm},
 \code{structure.learning.algorithm2}, \code{structure.learning.algorithm3} arguments and their
corresponding \code{structure.learning.args.list*} counterparts, many different configurations
can be used for the structure learning process, e.g. by using grow-shrink for D nodes with
distance set to 1, then injecting the left nodes using hill-climbing without distance
restriction.
\item \code{fix.intermediate}, if set to \code{TRUE}, will forbid the creation of new arcs
between nodes that were present in the previous learning step. E.g. if
\code{structure.learning.steps = c("local", "global\-past")}, no new arcs between D nodes
will be created in the second step, as the first DAG will be considered finished.
If set to \code{FALSE}, the previous step DAG will be kept, but the next
learning algorithm could create new arcs between D nodes over the first one.
}

\strong{Forbidding or Forcing Arcs}
\code{force.DD}, \code{forbid.GG}, \code{forbid.DD}, \code{forbid.DtoG}, \code{force.closest.GD},
\code{forbid.GD}, \code{fix.intermediate}, \code{structure.learning.steps} allow for
introducing constraints to the structure learning algorithm. The user might also combine them
with \code{structure.learning.args.list$whitelist} and
\code{structure.learning.args.list$blacklist}. As \code{whitelist} has priority over
 \code{blacklist}, i.e. an arc placed in both will always be present in the DAG, they provide
 maximum flexibility. Bearing the priority of the \code{whitelist}, \code{force.closest.GD = TRUE}
 and \code{forbid.GD = TRUE} will, for example, forbid the placement of \emph{aditional}
 arcs beyond those specified as the closest G-D.

 When manually specifying a whitelist or blacklist through \code{structure.learning.args.list},
 beware of the naming convention. It overrides the names and marks them as either "D.X" or "G.X",
 predictand and predictor nodes, respectivelly. A plot of a dummy network using \code{plotDBN()} 
 is may help.
}
\author{
Mikel N. Legasa
}
